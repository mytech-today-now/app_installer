<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Augment AI Prompt: Comprehensive Update Testing & Error Fixing</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: #f5f5f5;
            line-height: 1.6;
        }
        .prompt-container {
            background-color: white;
            padding: 30px;
            border-radius: 8px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        h1 {
            color: #0078d4;
            border-bottom: 3px solid #0078d4;
            padding-bottom: 10px;
        }
        h2 {
            color: #106ebe;
            margin-top: 30px;
            border-left: 4px solid #0078d4;
            padding-left: 15px;
        }
        h3 {
            color: #2b88d8;
            margin-top: 20px;
        }
        .section {
            margin: 20px 0;
            padding: 15px;
            background-color: #f9f9f9;
            border-left: 4px solid #0078d4;
        }
        .code-block {
            background-color: #1e1e1e;
            color: #d4d4d4;
            padding: 15px;
            border-radius: 5px;
            overflow-x: auto;
            font-family: 'Consolas', 'Courier New', monospace;
            margin: 10px 0;
        }
        .requirement {
            background-color: #fff4ce;
            padding: 10px;
            margin: 10px 0;
            border-left: 4px solid #ffb900;
        }
        .critical {
            background-color: #fde7e9;
            padding: 10px;
            margin: 10px 0;
            border-left: 4px solid #e81123;
            font-weight: bold;
        }
        .success {
            background-color: #dff6dd;
            padding: 10px;
            margin: 10px 0;
            border-left: 4px solid #107c10;
        }
        ul, ol {
            margin: 10px 0;
            padding-left: 30px;
        }
        li {
            margin: 5px 0;
        }
        .file-path {
            background-color: #e8e8e8;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Consolas', monospace;
            font-size: 0.9em;
        }
        .emphasis {
            color: #0078d4;
            font-weight: bold;
        }
    </style>
</head>
<body>
    <div class="prompt-container">
        <h1>ü§ñ Augment AI Prompt: Comprehensive Update Testing & Automated Error Fixing</h1>
        
        <div class="critical">
            <strong>‚ö†Ô∏è CRITICAL OBJECTIVE:</strong> Create a comprehensive PowerShell testing framework that systematically tests both <span class="file-path">install.ps1</span> and <span class="file-path">install-gui.ps1</span> update functionality, automatically detects errors, fixes them in both scripts, and ensures all updatable applications can be updated successfully without errors.
        </div>

        <h2>üìã Project Overview</h2>
        <div class="section">
            <p><strong>Goal:</strong> Generate PowerShell script(s) in <span class="file-path">Q:\_kyle\temp_documents\GitHub\PowerShellScripts\tools</span> that:</p>
            <ol>
                <li>Systematically test the update functionality of both <span class="file-path">install.ps1</span> (CLI) and <span class="file-path">install-gui.ps1</span> (GUI)</li>
                <li>Attempt to update ALL updatable applications using winget through the features of both scripts</li>
                <li>Detect and log any errors encountered during the update process</li>
                <li>Automatically analyze errors and generate fixes</li>
                <li>Apply fixes to BOTH <span class="file-path">install.ps1</span> AND <span class="file-path">install-gui.ps1</span></li>
                <li>Re-test after fixes to verify all updates complete successfully</li>
                <li>Generate comprehensive reports of all operations</li>
            </ol>
        </div>

        <h2>üéØ Detailed Requirements</h2>

        <h3>1. Script Generation Requirements</h3>
        <div class="requirement">
            <strong>Primary Script:</strong> <span class="file-path">Q:\_kyle\temp_documents\GitHub\PowerShellScripts\tools\Test-UpdateFunctionality.ps1</span>
            <ul>
                <li>Main orchestration script that coordinates all testing and fixing operations</li>
                <li>Must be fully automated with minimal user intervention</li>
                <li>Must support both interactive and unattended modes</li>
                <li>Must generate detailed logs and reports</li>
            </ul>
        </div>

        <div class="requirement">
            <strong>Supporting Scripts:</strong>
            <ul>
                <li><span class="file-path">tools\Analyze-UpdateErrors.ps1</span> - Error analysis and pattern detection</li>
                <li><span class="file-path">tools\Generate-ErrorFixes.ps1</span> - Automatic fix generation</li>
                <li><span class="file-path">tools\Apply-UpdateFixes.ps1</span> - Apply fixes to both install.ps1 and install-gui.ps1</li>
                <li><span class="file-path">tools\Report-UpdateResults.ps1</span> - Generate comprehensive HTML/Markdown reports</li>
            </ul>
        </div>

        <h3>2. Testing Methodology</h3>
        <div class="section">
            <h4>Phase 1: Discovery & Inventory</h4>
            <ol>
                <li><strong>Detect all updatable applications</strong> using <span class="file-path">winget upgrade --include-unknown</span></li>
                <li><strong>Create comprehensive inventory</strong> including:
                    <ul>
                        <li>Application Name</li>
                        <li>Package ID</li>
                        <li>Current Version</li>
                        <li>Available Version</li>
                        <li>Source (winget, msstore, etc.)</li>
                        <li>Dependencies (using the new Get-PackageDependencies function)</li>
                    </ul>
                </li>
                <li><strong>Categorize applications</strong> by complexity, size, and known issues</li>
                <li><strong>Create test plan</strong> with prioritization (critical apps first, then others)</li>
            </ol>

            <h4>Phase 2: CLI Testing (install.ps1)</h4>
            <ol>
                <li><strong>Source the install.ps1 script</strong> to load all functions into memory</li>
                <li><strong>Call Get-AvailableUpdates</strong> function to get update list</li>
                <li><strong>For each updatable application:</strong>
                    <ul>
                        <li>Create isolated test environment (backup current state)</li>
                        <li>Call Update-Applications function with single app</li>
                        <li>Monitor output, exit codes, and error streams</li>
                        <li>Capture all logs from <span class="file-path">C:\mytech.today\logs\</span></li>
                        <li>Verify update success by checking installed version</li>
                        <li>Record results (success/failure, error messages, timing)</li>
                    </ul>
                </li>
                <li><strong>Aggregate all errors</strong> and categorize by type</li>
            </ol>

            <h4>Phase 3: GUI Testing (install-gui.ps1)</h4>
            <ol>
                <li><strong>Launch install-gui.ps1</strong> in automated mode (if possible) or simulate user actions</li>
                <li><strong>Alternative approach:</strong> Source install-gui.ps1 and call functions directly (bypassing GUI)</li>
                <li><strong>For each updatable application:</strong>
                    <ul>
                        <li>Call the same Update-Applications function used by GUI</li>
                        <li>Monitor output and capture errors</li>
                        <li>Verify update success</li>
                        <li>Record results</li>
                    </ul>
                </li>
                <li><strong>Compare results</strong> between CLI and GUI modes</li>
                <li><strong>Identify discrepancies</strong> in error handling or behavior</li>
            </ol>

            <h4>Phase 4: Error Analysis</h4>
            <ol>
                <li><strong>Collect all errors</strong> from both CLI and GUI testing</li>
                <li><strong>Categorize errors</strong> by type:
                    <ul>
                        <li>Dependency errors (missing VCRedist, .NET, etc.)</li>
                        <li>Architecture mismatches (x86 vs x64)</li>
                        <li>Installer type issues (MSI, EXE, MSIX)</li>
                        <li>Network/download failures</li>
                        <li>Permission/elevation issues</li>
                        <li>Exit code errors (non-zero but successful)</li>
                        <li>Winget command failures</li>
                        <li>Script logic errors</li>
                    </ul>
                </li>
                <li><strong>Identify patterns</strong> in errors (same error across multiple apps)</li>
                <li><strong>Prioritize fixes</strong> by impact (how many apps affected)</li>
            </ol>

            <h4>Phase 5: Automatic Fix Generation</h4>
            <ol>
                <li><strong>For each error category, generate appropriate fixes:</strong>
                    <ul>
                        <li><strong>Dependency errors:</strong> Enhance Get-PackageDependencies and Install-PackageDependencies functions</li>
                        <li><strong>Architecture mismatches:</strong> Add architecture detection and filtering</li>
                        <li><strong>Installer type issues:</strong> Add installer type validation and fallback logic</li>
                        <li><strong>Exit code errors:</strong> Enhance exit code handling with more success patterns</li>
                        <li><strong>Winget command failures:</strong> Add retry logic, alternative commands, or parameter adjustments</li>
                        <li><strong>Script logic errors:</strong> Fix bugs in conditional logic, error handling, or flow control</li>
                    </ul>
                </li>
                <li><strong>Generate code patches</strong> for both install.ps1 and install-gui.ps1</li>
                <li><strong>Ensure consistency</strong> between CLI and GUI versions</li>
            </ol>

            <h4>Phase 6: Fix Application</h4>
            <ol>
                <li><strong>Backup original scripts</strong> to <span class="file-path">app_installer\backups\</span> with timestamp</li>
                <li><strong>Apply fixes to install.ps1</strong> using str-replace-editor or similar</li>
                <li><strong>Apply identical fixes to install-gui.ps1</strong> (accounting for GUI-specific code)</li>
                <li><strong>Validate syntax</strong> of modified scripts (PowerShell -Syntax check)</li>
                <li><strong>Create detailed changelog</strong> documenting all changes</li>
            </ol>

            <h4>Phase 7: Re-Testing & Verification</h4>
            <ol>
                <li><strong>Re-run all tests</strong> with fixed scripts</li>
                <li><strong>Verify all previously failing updates now succeed</strong></li>
                <li><strong>Ensure no regressions</strong> (previously working updates still work)</li>
                <li><strong>If new errors found:</strong> Return to Phase 4 and iterate</li>
                <li><strong>Continue until:</strong> All updatable apps update successfully OR maximum iteration limit reached</li>
            </ol>

            <h4>Phase 8: Reporting</h4>
            <ol>
                <li><strong>Generate comprehensive HTML report</strong> including:
                    <ul>
                        <li>Executive summary (total apps, success rate, errors fixed)</li>
                        <li>Detailed test results for each application</li>
                        <li>Error analysis with categorization</li>
                        <li>Fixes applied with before/after code comparison</li>
                        <li>Performance metrics (time per update, total time)</li>
                        <li>Recommendations for future improvements</li>
                    </ul>
                </li>
                <li><strong>Generate Markdown summary</strong> for easy reading</li>
                <li><strong>Save all logs</strong> to <span class="file-path">C:\mytech.today\logs\update_testing\</span></li>
            </ol>
        </div>

        <h3>3. Code Structure Requirements</h3>
        <div class="section">
            <h4>Test-UpdateFunctionality.ps1 Structure</h4>
            <div class="code-block">
# Main orchestration script
[CmdletBinding()]
param(
    [switch]$UnattendedMode,
    [switch]$SkipBackup,
    [int]$MaxIterations = 3,
    [string]$LogPath = "C:\mytech.today\logs\update_testing",
    [string]$ReportPath = "C:\mytech.today\reports\update_testing"
)

# Import required modules and functions
. "$PSScriptRoot\..\app_installer\install.ps1"

# Phase 1: Discovery
function Get-UpdatableApplications { }

# Phase 2-3: Testing
function Test-CLIUpdates { }
function Test-GUIUpdates { }

# Phase 4: Analysis
function Analyze-UpdateErrors { }

# Phase 5: Fix Generation
function Generate-ErrorFixes { }

# Phase 6: Application
function Apply-FixesToScripts { }

# Phase 7: Verification
function Verify-UpdateFixes { }

# Phase 8: Reporting
function New-UpdateTestingReport { }

# Main execution flow
try {
    Write-Host "Starting comprehensive update testing..." -ForegroundColor Cyan
    
    # Discovery
    $apps = Get-UpdatableApplications
    
    # Testing
    $cliResults = Test-CLIUpdates -Applications $apps
    $guiResults = Test-GUIUpdates -Applications $apps
    
    # Analysis
    $errors = Analyze-UpdateErrors -CLIResults $cliResults -GUIResults $guiResults
    
    # Iterative fixing
    $iteration = 0
    while ($errors.Count -gt 0 -and $iteration -lt $MaxIterations) {
        $iteration++
        
        # Generate fixes
        $fixes = Generate-ErrorFixes -Errors $errors
        
        # Apply fixes
        Apply-FixesToScripts -Fixes $fixes
        
        # Re-test
        $cliResults = Test-CLIUpdates -Applications $apps
        $guiResults = Test-GUIUpdates -Applications $apps
        
        # Re-analyze
        $errors = Analyze-UpdateErrors -CLIResults $cliResults -GUIResults $guiResults
    }
    
    # Generate report
    New-UpdateTestingReport -CLIResults $cliResults -GUIResults $guiResults -Fixes $fixes
}
catch {
    Write-Error "Critical error in testing framework: $_"
}
            </div>
        </div>

        <h3>4. Error Detection Patterns</h3>
        <div class="section">
            <p>The testing framework must detect and handle these common error patterns:</p>
            <ul>
                <li><strong>Exit Code Errors:</strong> Non-zero exit codes that may or may not indicate failure</li>
                <li><strong>Output Pattern Errors:</strong> Error messages in stdout/stderr like "No applicable installer found"</li>
                <li><strong>Dependency Errors:</strong> Missing dependencies causing installation failures</li>
                <li><strong>Timeout Errors:</strong> Updates taking too long or hanging</li>
                <li><strong>Network Errors:</strong> Download failures, connection issues</li>
                <li><strong>Permission Errors:</strong> Insufficient privileges for certain operations</li>
                <li><strong>Version Detection Errors:</strong> Unable to verify if update succeeded</li>
                <li><strong>Concurrent Update Errors:</strong> Conflicts when multiple updates run</li>
            </ul>
        </div>

        <h3>5. Fix Generation Logic</h3>
        <div class="section">
            <p>For each error type, the framework should generate appropriate fixes:</p>
            
            <h4>Dependency Error Fixes</h4>
            <ul>
                <li>Enhance Get-PackageDependencies to detect more dependency types</li>
                <li>Add Windows Feature dependency detection</li>
                <li>Improve Install-PackageDependencies error handling</li>
                <li>Add dependency version checking</li>
            </ul>

            <h4>Exit Code Error Fixes</h4>
            <ul>
                <li>Expand success pattern matching in Update-Applications</li>
                <li>Add more exit codes to "success despite non-zero" list</li>
                <li>Improve output parsing for success indicators</li>
            </ul>

            <h4>Architecture Error Fixes</h4>
            <ul>
                <li>Add system architecture detection</li>
                <li>Filter packages by compatible architecture</li>
                <li>Add --architecture parameter to winget commands</li>
            </ul>

            <h4>Timeout Error Fixes</h4>
            <ul>
                <li>Add timeout parameters to winget commands</li>
                <li>Implement retry logic with exponential backoff</li>
                <li>Add progress monitoring to detect hangs</li>
            </ul>
        </div>

        <h3>6. Logging Requirements</h3>
        <div class="requirement">
            <strong>All operations must be logged with:</strong>
            <ul>
                <li>Timestamp (ISO 8601 format)</li>
                <li>Log level (INFO, WARNING, ERROR, SUCCESS)</li>
                <li>Operation phase (Discovery, Testing, Analysis, Fixing, Verification)</li>
                <li>Application name and ID</li>
                <li>Detailed error messages with stack traces</li>
                <li>Performance metrics (duration, memory usage)</li>
            </ul>
            
            <strong>Log files:</strong>
            <ul>
                <li><span class="file-path">C:\mytech.today\logs\update_testing\master_log_{timestamp}.log</span></li>
                <li><span class="file-path">C:\mytech.today\logs\update_testing\cli_test_{timestamp}.log</span></li>
                <li><span class="file-path">C:\mytech.today\logs\update_testing\gui_test_{timestamp}.log</span></li>
                <li><span class="file-path">C:\mytech.today\logs\update_testing\errors_{timestamp}.log</span></li>
                <li><span class="file-path">C:\mytech.today\logs\update_testing\fixes_{timestamp}.log</span></li>
            </ul>
        </div>

        <h3>7. Report Generation Requirements</h3>
        <div class="success">
            <strong>Generate comprehensive HTML report with:</strong>
            <ul>
                <li><strong>Executive Summary:</strong> Total apps tested, success rate, errors found, fixes applied</li>
                <li><strong>Application Results Table:</strong> Sortable/filterable table with all test results</li>
                <li><strong>Error Analysis:</strong> Charts showing error distribution by category</li>
                <li><strong>Fix Details:</strong> Before/after code comparison for each fix</li>
                <li><strong>Performance Metrics:</strong> Time per update, total duration, resource usage</li>
                <li><strong>Recommendations:</strong> Suggested improvements for future</li>
            </ul>
        </div>

        <h2>üîß Implementation Details</h2>

        <h3>Key Functions to Leverage from Existing Scripts</h3>
        <div class="section">
            <p>The testing framework should use these existing functions:</p>
            <ul>
                <li><span class="file-path">install.ps1</span> and <span class="file-path">install-gui.ps1</span>:
                    <ul>
                        <li><strong>Get-AvailableUpdates:</strong> Get list of updatable applications</li>
                        <li><strong>Update-Applications:</strong> Perform updates</li>
                        <li><strong>Get-PackageDependencies:</strong> Detect dependencies</li>
                        <li><strong>Install-PackageDependencies:</strong> Install dependencies</li>
                        <li><strong>Write-Log:</strong> Logging functionality</li>
                        <li><strong>Test-WingetAvailable:</strong> Verify winget is available</li>
                    </ul>
                </li>
            </ul>
        </div>

        <h3>Critical Success Criteria</h3>
        <div class="critical">
            <strong>The testing framework is successful when:</strong>
            <ol>
                <li>‚úÖ ALL updatable applications can be updated without errors</li>
                <li>‚úÖ Both install.ps1 and install-gui.ps1 have identical update success rates</li>
                <li>‚úÖ All fixes are applied to BOTH scripts consistently</li>
                <li>‚úÖ Comprehensive logs and reports are generated</li>
                <li>‚úÖ The framework can run unattended without user intervention</li>
                <li>‚úÖ All errors are categorized and analyzed</li>
                <li>‚úÖ Fixes are automatically generated and applied</li>
                <li>‚úÖ Re-testing verifies all fixes work correctly</li>
            </ol>
        </div>

        <h2>üìù Deliverables</h2>
        <div class="section">
            <ol>
                <li><strong>Primary Script:</strong> <span class="file-path">tools\Test-UpdateFunctionality.ps1</span></li>
                <li><strong>Supporting Scripts:</strong> All helper scripts in <span class="file-path">tools\</span> directory</li>
                <li><strong>Documentation:</strong> <span class="file-path">tools\README_UPDATE_TESTING.md</span> with usage instructions</li>
                <li><strong>Fixed Scripts:</strong> Updated <span class="file-path">install.ps1</span> and <span class="file-path">install-gui.ps1</span></li>
                <li><strong>Backups:</strong> Original scripts in <span class="file-path">app_installer\backups\</span></li>
                <li><strong>Reports:</strong> HTML and Markdown reports in <span class="file-path">C:\mytech.today\reports\update_testing\</span></li>
                <li><strong>Logs:</strong> All test logs in <span class="file-path">C:\mytech.today\logs\update_testing\</span></li>
            </ol>
        </div>

        <h2>üöÄ Execution Instructions</h2>
        <div class="section">
            <h4>For Augment AI:</h4>
            <ol>
                <li>Read and analyze both <span class="file-path">install.ps1</span> and <span class="file-path">install-gui.ps1</span></li>
                <li>Understand all existing functions, especially update-related ones</li>
                <li>Generate <span class="file-path">Test-UpdateFunctionality.ps1</span> with all required phases</li>
                <li>Generate all supporting scripts</li>
                <li>Create comprehensive documentation</li>
                <li>Test the testing framework itself (meta-testing)</li>
                <li>Run the framework and fix any errors in both install scripts</li>
                <li>Generate final reports</li>
            </ol>
        </div>

        <div class="success">
            <h3>‚ú® Expected Outcome</h3>
            <p>After running this testing framework, both <span class="file-path">install.ps1</span> and <span class="file-path">install-gui.ps1</span> should be able to successfully update ALL updatable applications on the system without any errors, with comprehensive logging and reporting of the entire process.</p>
        </div>
    </div>
</body>
</html>

